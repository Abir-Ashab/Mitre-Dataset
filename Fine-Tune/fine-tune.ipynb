{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Us5viIU19TI",
    "outputId": "cd14f111-e640-48c0-8323-f368cb27521b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Kaggle data path\n",
    "data_path = \"/kaggle/input/mitre-datset\"\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    files = os.listdir(data_path)\n",
    "    print(\"üìÇ Files in data folder:\")\n",
    "    for f in files:\n",
    "        size = os.path.getsize(os.path.join(data_path, f)) / (1024**2)\n",
    "        print(f\"   {f}: {size:.1f} MB\")\n",
    "    \n",
    "    # Verify JSONL\n",
    "    import json\n",
    "    for filename in ['train.jsonl', 'val.jsonl', 'test.jsonl']:\n",
    "        filepath = os.path.join(data_path, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                count = sum(1 for _ in f)\n",
    "            print(f\"‚úÖ {filename}: {count:,} examples\")\n",
    "        else:\n",
    "            print(f\"‚ùå {filename}: NOT FOUND\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found!\")\n",
    "    print(\"üìå Upload data: Click 'Add Data' > 'Upload' > 'New Dataset'\")\n",
    "    print(\"   Name it: mitre-dataset\")\n",
    "    print(\"   Upload: train.jsonl, val.jsonl, test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"üì¶ Installing dependencies...\")\n",
    "!pip install -q transformers datasets accelerate peft\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ft7IA_LO2jAh",
    "outputId": "ea780d55-a30e-48cd-f085-545965ecee00",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 4: Configuration for Kaggle\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"  # 1.5B fits well in GPU\n",
    "\n",
    "# Kaggle paths (CHANGED from Colab)\n",
    "DATA_PATH = \"/kaggle/input/mitre-datset\"\n",
    "OUTPUT_DIR = \"/kaggle/working/checkpoints\"\n",
    "FINAL_MODEL_DIR = \"/kaggle/working/fine_tuned_model\"\n",
    "\n",
    "TRAIN_FILE = f\"{DATA_PATH}/train.jsonl\"\n",
    "VAL_FILE = f\"{DATA_PATH}/val.jsonl\"\n",
    "\n",
    "# Training settings - OPTIMIZED for 7-log chunks with DYNAMIC PADDING\n",
    "MAX_LENGTH = 4096        # Optimized for 7-log chunks (~2,200 tokens + instruction = ~3,000 total)\n",
    "                         # Maximum length for truncation only (not padding!)\n",
    "                         # Each batch will pad to its longest example (not MAX_LENGTH)\n",
    "BATCH_SIZE = 4           # Increased from 1 (7-log chunks are much smaller!)\n",
    "GRAD_ACCUM_STEPS = 4     # Reduced from 16 (effective batch = 4 * 4 = 16)\n",
    "NUM_EPOCHS = 5           # Increased from 2 for better learning\n",
    "LEARNING_RATE = 3e-4     # Slightly higher for better convergence with larger batches\n",
    "\n",
    "print(\"‚úÖ Configuration loaded (Kaggle)\")\n",
    "print(f\"   Model: {MODEL_NAME}\")\n",
    "print(f\"   MAX_LENGTH: {MAX_LENGTH} tokens (optimized for 7-log chunks)\")\n",
    "print(f\"   Batch size: {BATCH_SIZE} (increased for smaller chunks!)\")\n",
    "print(f\"   Effective batch: {BATCH_SIZE * GRAD_ACCUM_STEPS}\")\n",
    "print(f\"   Dynamic padding: Each batch pads to its longest example\")\n",
    "print(f\"   Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   LoRA: r=32, alpha=64 (increased capacity)\")\n",
    "print(f\"   Estimated time: ~3-4 hours (faster with optimized batch size!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Load model WITHOUT quantization (T4 has 15GB, should fit)\n",
    "print(\"\\nüîÑ Loading model...\")\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,  # Use FP16 instead of 4-bit\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {MODEL_NAME}\")\n",
    "print(f\"üìä GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB / 15 GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4Nj92VwO1JZ",
    "outputId": "f1e1c788-3207-4ef9-8618-5d8b3f041448",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 6: Configure LoRA (REQUIRED!)\n",
    "print(\"\\nüîÑ Configuring LoRA...\")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Enable gradient checkpointing and disable cache\n",
    "model.gradient_checkpointing_enable()\n",
    "model.config.use_cache = False  # CRITICAL: Required for gradient checkpointing\n",
    "\n",
    "# Prepare model for training\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze base model\n",
    "    if param.ndim == 1:\n",
    "        param.data = param.data.to(torch.float32)  # Cast layer norms to fp32\n",
    "\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,                # Increased from 16 for better capacity with longer sequences\n",
    "    lora_alpha=64,       # Increased from 32 (alpha = 2 * r)\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "print(\"‚úÖ LoRA configured\")\n",
    "print(f\"üìä GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB / 15 GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Load dataset\n",
    "print(\"\\nüîÑ Loading dataset...\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    'json',\n",
    "    data_files={\n",
    "        'train': TRAIN_FILE,\n",
    "        'validation': VAL_FILE\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded:\")\n",
    "print(f\"   Training: {len(dataset['train'])} examples\")\n",
    "print(f\"   Validation: {len(dataset['validation'])} examples\")\n",
    "print(f\"\\nüìã Sample entry:\")\n",
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7b: Analyze actual token lengths in your data\n",
    "print(\"\\nüîç Analyzing token lengths in your dataset...\")\n",
    "print(\"This helps determine if MAX_LENGTH needs adjustment\\n\")\n",
    "\n",
    "# Sample random examples to check lengths\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "sample_size = min(1000, len(dataset['train']))\n",
    "sample_indices = random.sample(range(len(dataset['train'])), sample_size)\n",
    "\n",
    "token_lengths = []\n",
    "\n",
    "for idx in sample_indices:\n",
    "    example = dataset['train'][idx]\n",
    "    formatted = f\"\"\"{example['instruction']}\n",
    "\n",
    "### Input:\n",
    "{example['input']}\n",
    "\n",
    "### Response:\n",
    "{example['output']}\"\"\"\n",
    "    \n",
    "    # Tokenize without truncation to see actual length\n",
    "    tokens = tokenizer(formatted, truncation=False)\n",
    "    token_lengths.append(len(tokens['input_ids']))\n",
    "\n",
    "# Statistics\n",
    "import numpy as np\n",
    "token_lengths = np.array(token_lengths)\n",
    "\n",
    "print(f\"üìä Token Length Statistics ({sample_size} examples):\")\n",
    "print(f\"   Min:     {token_lengths.min():,} tokens\")\n",
    "print(f\"   Max:     {token_lengths.max():,} tokens\")\n",
    "print(f\"   Mean:    {token_lengths.mean():,.0f} tokens\")\n",
    "print(f\"   Median:  {np.median(token_lengths):,.0f} tokens\")\n",
    "print(f\"   95th %:  {np.percentile(token_lengths, 95):,.0f} tokens\")\n",
    "print(f\"   99th %:  {np.percentile(token_lengths, 99):,.0f} tokens\")\n",
    "\n",
    "# Check if MAX_LENGTH is sufficient\n",
    "if token_lengths.max() > MAX_LENGTH:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: Some examples exceed MAX_LENGTH ({MAX_LENGTH})!\")\n",
    "    over_limit = (token_lengths > MAX_LENGTH).sum()\n",
    "    print(f\"   {over_limit} examples ({over_limit/sample_size*100:.1f}%) will be truncated\")\n",
    "    print(f\"   Consider increasing MAX_LENGTH to {int(np.percentile(token_lengths, 99))} (99th percentile)\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ MAX_LENGTH ({MAX_LENGTH}) is sufficient for all examples\")\n",
    "    recommended = int(np.percentile(token_lengths, 99))\n",
    "    print(f\"   Recommended MAX_LENGTH: {recommended} (99th percentile)\")\n",
    "\n",
    "print(f\"\\nüí° BENEFITS OF DYNAMIC PADDING:\")\n",
    "print(f\"   Without: Every example padded to {MAX_LENGTH} = {MAX_LENGTH:,} tokens/example\")\n",
    "print(f\"   With:    Average padding to {token_lengths.mean():,.0f} tokens/example\")\n",
    "print(f\"   Savings: {(1 - token_lengths.mean()/MAX_LENGTH)*100:.1f}% less computation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "80df8959943346319aa857a012675ec3",
      "fcd1bd417b9a4087b916d7aef75b51be",
      "26db7ffd01514fd69ccc6e1205083211",
      "9deb1dda55db4ae9a757a98724fc8634",
      "93eeb1b6efe2469f8fae0842fe182182",
      "a564b41fcdea4797a01a4fd01e2a7d8a",
      "3ab10afd37d6443c8a2d4ef7f35c5461",
      "b7539d2b59be4d3d9124d33732116090",
      "fba5a73dd7684c80a1fe395a6387cace",
      "9d4d2aa36da2402eae751a459dcc8745",
      "5a27bfcc07be4fe29efa405da57a3b67",
      "3c5983a49b9f46299f8e507fcefdd39c",
      "b1352830aaa443e69f0a0205aa81e0e9",
      "ea377145d602424492736c9b3d455d12",
      "51ae826fe33643edb97775174439dfdb",
      "bec83df5b3ad42faac9123b997de2169",
      "d2cf22c7bc634e48a3e12c398c8c04b9",
      "877c9f821c9641ca9815761c9914fa76",
      "9cbb8c048f59433abe10c51618bfdc9b",
      "d7ce60214b664461b6b4c64ceb468eae",
      "72df0825a21c4b98afe1c0fe34e5b9c4",
      "9a0141597ff844c5bb2ca50bae7a46ea"
     ]
    },
    "id": "GhRQVH-dPQ6u",
    "outputId": "bb1ddc12-7292-4429-fc52-b6ca5a46f745",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 8: Format and tokenize dataset\n",
    "print(\"\\nüîÑ Formatting and tokenizing dataset...\")\n",
    "\n",
    "# Dataset has columns: instruction, input, output\n",
    "print(f\"Dataset columns: {dataset['train'].column_names}\")\n",
    "\n",
    "def format_prompt(example):\n",
    "    # Combine instruction + input + output into training format\n",
    "    return f\"\"\"{example['instruction']}\n",
    "\n",
    "### Input:\n",
    "{example['input']}\n",
    "\n",
    "### Response:\n",
    "{example['output']}\"\"\"\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Format each example\n",
    "    texts = [\n",
    "        format_prompt({\n",
    "            'instruction': inst,\n",
    "            'input': inp,\n",
    "            'output': out\n",
    "        })\n",
    "        for inst, inp, out in zip(\n",
    "            examples['instruction'],\n",
    "            examples['input'],\n",
    "            examples['output']\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Tokenize with DYNAMIC PADDING (no padding here - let DataCollator handle it)\n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=False  # NO padding here! DataCollator will pad each batch dynamically\n",
    "    )\n",
    "\n",
    "    # CRITICAL: Mask instruction/input in labels - only compute loss on Response!\n",
    "    # This makes the model focus on learning to generate good responses\n",
    "    labels = []\n",
    "    for i, (text, input_ids) in enumerate(zip(texts, tokenized['input_ids'])):\n",
    "        # Find where \"### Response:\" starts\n",
    "        response_marker = \"### Response:\"\n",
    "        response_start = text.find(response_marker)\n",
    "        \n",
    "        if response_start != -1:\n",
    "            # Tokenize up to response marker to find the position\n",
    "            text_before_response = text[:response_start + len(response_marker)]\n",
    "            tokens_before = tokenizer(text_before_response, add_special_tokens=False)['input_ids']\n",
    "            response_token_start = len(tokens_before)\n",
    "            \n",
    "            # Create label with masking (-100 = ignore in loss computation)\n",
    "            label = [-100] * response_token_start + input_ids[response_token_start:]\n",
    "        else:\n",
    "            # Fallback: use all tokens if marker not found\n",
    "            label = input_ids.copy()\n",
    "        \n",
    "        labels.append(label)\n",
    "    \n",
    "    tokenized[\"labels\"] = labels\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "print(\"\\nüîÑ Tokenizing...\")\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset['train'].column_names\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dataset tokenized\")\n",
    "print(f\"   Training: {len(tokenized_dataset['train'])} examples\")\n",
    "print(f\"   Validation: {len(tokenized_dataset['validation'])} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Set up training arguments with better evaluation\n",
    "print(\"\\nüîÑ Setting up training arguments...\")\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "import numpy as np\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,     # Optimized for 7-log chunks (~3000 tokens)\n",
    "    per_device_eval_batch_size=BATCH_SIZE,      # Match training batch size\n",
    "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,  # Effective batch = 4 * 4 = 16\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    fp16=True,\n",
    "    logging_steps=25,                           # More frequent logging\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,                             # Evaluate more frequently (every 100 steps)\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,                             # Save more frequently\n",
    "    save_total_limit=3,                         # Keep 3 best checkpoints\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,                    # Lower loss is better\n",
    "    warmup_ratio=0.1,                           # 10% warmup for better stability\n",
    "    weight_decay=0.01,                          # Weight decay for regularization\n",
    "    max_grad_norm=1.0,                          # Gradient clipping\n",
    "    optim=\"adamw_torch\",\n",
    "    adam_beta1=0.9,                             # AdamW beta1\n",
    "    adam_beta2=0.999,                           # AdamW beta2\n",
    "    adam_epsilon=1e-8,                          # AdamW epsilon\n",
    "    lr_scheduler_type=\"cosine\",                 # Cosine learning rate schedule\n",
    "    label_smoothing_factor=0.1,                 # Label smoothing for better generalization\n",
    "    report_to=\"none\",\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    logging_first_step=True,\n",
    "    logging_nan_inf_filter=True,\n",
    "    dataloader_num_workers=2,                   # Parallel data loading\n",
    "    dataloader_pin_memory=True,                 # Faster GPU transfer\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training arguments configured\")\n",
    "print(f\"   Batch size: {BATCH_SIZE} per device (optimized for 7-log chunks)\")\n",
    "print(f\"   Effective batch size: {BATCH_SIZE * GRAD_ACCUM_STEPS}\")\n",
    "print(f\"   Total steps: ~{len(tokenized_dataset['train']) // (BATCH_SIZE * GRAD_ACCUM_STEPS) * NUM_EPOCHS}\")\n",
    "print(f\"   Learning rate: {LEARNING_RATE} (cosine schedule with 10% warmup)\")\n",
    "print(f\"   Weight decay: 0.01, Label smoothing: 0.1\")\n",
    "print(f\"   Eval frequency: every 100 steps (more frequent monitoring)\")\n",
    "print(f\"   üéØ Loss computed ONLY on Response (instruction/input masked)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s5w9caxMRNtG",
    "outputId": "e80d4b11-ca25-436c-d5cf-527030e7f51a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 10: Create Trainer with early stopping\n",
    "print(\"\\nüîÑ Creating trainer...\")\n",
    "\n",
    "from transformers import Trainer, DataCollatorForLanguageModeling, EarlyStoppingCallback\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Add early stopping to prevent overfitting\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=5,  # Stop if no improvement for 5 evals (more patience)\n",
    "    early_stopping_threshold=0.005  # Smaller threshold for finer control\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer created with early stopping\")\n",
    "print(f\"   Early stopping patience: 5 evaluations\")\n",
    "print(f\"   Will stop if loss doesn't improve by 0.005\")\n",
    "print(f\"   Label smoothing: 0.1 (better generalization)\")\n",
    "print(f\"   Response-only loss: Ignores instruction/input tokens\")\n",
    "\n",
    "print(f\"üìä GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB / 15 GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Start training with progress tracking\n",
    "print(\"\\nüöÄ Starting training...\\n\")\n",
    "print(\"üí° OPTIMIZED TRAINING CONFIGURATION:\")\n",
    "print(f\"   Data: 7-log chunks (~2,200 tokens each)\")\n",
    "print(f\"   MAX_LENGTH: {MAX_LENGTH} tokens (plenty of headroom)\")\n",
    "print(f\"   Batch size: {BATCH_SIZE} (4x faster than before!)\")\n",
    "print(f\"   Effective batch: {BATCH_SIZE * GRAD_ACCUM_STEPS}\")\n",
    "print(f\"   NUM_EPOCHS: {NUM_EPOCHS}\")\n",
    "print(f\"   LoRA: r={32}, alpha={64}\")\n",
    "print(f\"   Learning rate: {LEARNING_RATE} with cosine schedule\")\n",
    "print(f\"   Label smoothing: 0.1 (better generalization)\")\n",
    "print(f\"   üéØ Response-only loss (ignores instruction/input)\")\n",
    "print(f\"\\n‚è±Ô∏è Estimated time: ~3-4 hours (faster with optimized batching!)\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train and capture results\n",
    "train_result = trainer.train()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ TRAINING COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚è±Ô∏è Total time: {elapsed_time/3600:.2f} hours ({elapsed_time/60:.1f} minutes)\")\n",
    "print(f\"üìä Final training loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"üìä Total steps: {train_result.global_step}\")\n",
    "\n",
    "# Get final evaluation metrics\n",
    "print(\"\\nüîÑ Running final evaluation...\")\n",
    "final_metrics = trainer.evaluate()\n",
    "print(f\"üìä Final validation loss: {final_metrics['eval_loss']:.4f}\")\n",
    "print(f\"üìä Perplexity: {np.exp(final_metrics['eval_loss']):.2f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dxkHqoHRSJX",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 12: Save the fine-tuned model\n",
    "print(\"\\nüíæ Saving model...\")\n",
    "\n",
    "model.save_pretrained(FINAL_MODEL_DIR)\n",
    "tokenizer.save_pretrained(FINAL_MODEL_DIR)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {FINAL_MODEL_DIR}\")\n",
    "print(\"\\nüì• Download model:\")\n",
    "print(\"   See next cell to create download link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Download model from Kaggle\n",
    "import os\n",
    "\n",
    "print(\"üì¶ Creating downloadable zip...\")\n",
    "\n",
    "# Zip the model\n",
    "!zip -r fine_tuned_model.zip {FINAL_MODEL_DIR}\n",
    "\n",
    "print(f\"‚úÖ Model zipped: fine_tuned_model.zip\")\n",
    "print(f\"   Size: {os.path.getsize('fine_tuned_model.zip') / (1024**2):.1f} MB\")\n",
    "print(\"\\nüì• Download: Check the 'Output' section on the right\")\n",
    "print(\"   Click on fine_tuned_model.zip to download\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9103706,
     "sourceId": 14266243,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03ffadd6242f4a6aa54f6c273feb4982": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14af00e9fee84130a851af73dcb54954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5045fede23f048e787d057175febf279",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_03ffadd6242f4a6aa54f6c273feb4982",
      "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
     }
    },
    "17f6ef3c8ed54c5babfa6ce09d241427": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26db7ffd01514fd69ccc6e1205083211": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7539d2b59be4d3d9124d33732116090",
      "max": 31409,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fba5a73dd7684c80a1fe395a6387cace",
      "value": 31409
     }
    },
    "3544f8531fe94c4c8260a9639d26afcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ab10afd37d6443c8a2d4ef7f35c5461": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c5983a49b9f46299f8e507fcefdd39c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b1352830aaa443e69f0a0205aa81e0e9",
       "IPY_MODEL_ea377145d602424492736c9b3d455d12",
       "IPY_MODEL_51ae826fe33643edb97775174439dfdb"
      ],
      "layout": "IPY_MODEL_bec83df5b3ad42faac9123b997de2169"
     }
    },
    "5045fede23f048e787d057175febf279": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51ae826fe33643edb97775174439dfdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72df0825a21c4b98afe1c0fe34e5b9c4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9a0141597ff844c5bb2ca50bae7a46ea",
      "value": "‚Äá3717/3717‚Äá[00:44&lt;00:00,‚Äá86.95‚Äáexamples/s]"
     }
    },
    "5a27bfcc07be4fe29efa405da57a3b67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72df0825a21c4b98afe1c0fe34e5b9c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80df8959943346319aa857a012675ec3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fcd1bd417b9a4087b916d7aef75b51be",
       "IPY_MODEL_26db7ffd01514fd69ccc6e1205083211",
       "IPY_MODEL_9deb1dda55db4ae9a757a98724fc8634"
      ],
      "layout": "IPY_MODEL_93eeb1b6efe2469f8fae0842fe182182"
     }
    },
    "84957a4b45d64ed599b6fd6d6a26c38a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcbdb357421f4fbf9295890dcfa9012a",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec65741d34544d19a1b4aa81fc3bb132",
      "value": 2
     }
    },
    "877c9f821c9641ca9815761c9914fa76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93eeb1b6efe2469f8fae0842fe182182": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a0141597ff844c5bb2ca50bae7a46ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9cbb8c048f59433abe10c51618bfdc9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d4d2aa36da2402eae751a459dcc8745": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9deb1dda55db4ae9a757a98724fc8634": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d4d2aa36da2402eae751a459dcc8745",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5a27bfcc07be4fe29efa405da57a3b67",
      "value": "‚Äá31409/31409‚Äá[06:09&lt;00:00,‚Äá93.26‚Äáexamples/s]"
     }
    },
    "a564b41fcdea4797a01a4fd01e2a7d8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1352830aaa443e69f0a0205aa81e0e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2cf22c7bc634e48a3e12c398c8c04b9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_877c9f821c9641ca9815761c9914fa76",
      "value": "Map:‚Äá100%"
     }
    },
    "b4303b3066cd42d3b456368d7bba01d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f59f122813254af3beb3e4c9c7884e12",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3544f8531fe94c4c8260a9639d26afcd",
      "value": "‚Äá2/2‚Äá[00:30&lt;00:00,‚Äá14.75s/it]"
     }
    },
    "b7539d2b59be4d3d9124d33732116090": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcbdb357421f4fbf9295890dcfa9012a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bec83df5b3ad42faac9123b997de2169": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2cf22c7bc634e48a3e12c398c8c04b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7ce60214b664461b6b4c64ceb468eae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dea7e0c66a8e4807831ceb761abcd19c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14af00e9fee84130a851af73dcb54954",
       "IPY_MODEL_84957a4b45d64ed599b6fd6d6a26c38a",
       "IPY_MODEL_b4303b3066cd42d3b456368d7bba01d3"
      ],
      "layout": "IPY_MODEL_17f6ef3c8ed54c5babfa6ce09d241427"
     }
    },
    "ea377145d602424492736c9b3d455d12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cbb8c048f59433abe10c51618bfdc9b",
      "max": 3717,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7ce60214b664461b6b4c64ceb468eae",
      "value": 3717
     }
    },
    "ec65741d34544d19a1b4aa81fc3bb132": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f59f122813254af3beb3e4c9c7884e12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fba5a73dd7684c80a1fe395a6387cace": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fcd1bd417b9a4087b916d7aef75b51be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a564b41fcdea4797a01a4fd01e2a7d8a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_3ab10afd37d6443c8a2d4ef7f35c5461",
      "value": "Map:‚Äá100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
